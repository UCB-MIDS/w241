#+TITLE: Experiments and Causality 
#+OPTIONS: toc:nil 

* Schedule

| Week | Topics                                  | Async Reading                                   | Sync Reading                                                            | Assignment Due           |
|------+-----------------------------------------+-------------------------------------------------+-------------------------------------------------------------------------+--------------------------|
|    1 | Experimentation                         | [[./readings/GerberGreen.2012_1.pdf][FE 1]], [[http://www.nytimes.com/2007/09/16/magazine/16epidemiology-t.html][NYT]]                                       | [[./readings/Feynman.1974.pdf][Feynman]], News [[http://www.cbsnews.com/2100-204_162-570634.html][1]], [[https://www.nytimes.com/interactive/2018/07/18/upshot/nike-vaporfly-shoe-strava.html][2]], [[./readings/Athey.2017.pdf][Predict or Cause]]                                    | --                       |
|    2 | Apples to Apples                        | FE 2; [[./readings/LewisReiley.pdf][Lewis & Reiley]] (p. 1-2.5, §1; §2A-B)      | MTGI 1,5,8,9;  [[http://www.lse.ac.uk/philosophy/science-and-pseudoscience-overview-and-transcript/][Lakatos]] (O) [[https://github.com/UCB-MIDS/w241/blob/master/readings/Rubin.2008.pdf][Rubin]], sections 1 & 2                        | [[./assignments/essays/essay1][Essay 1 Draft]]            |
|    3 | Quantifying Uncertainty                 | FE 3.0, 3.1, 3.4                                | [[./readings/Blackwell.2013.pdf][Blackwell]], [[./readings/Lewis.Rao.2015.pdf][Lewis and Rao]] 1, 3.1, 3.2                                    | [[./assignments/README.md][PS 1]], Revised Essay 1    |
|    4 | Blocking and Clustering                 | FE 3.6.1, 3.6.2, 4.4, 4.5                       | (O): [[./readings/Cameron_Miller_Cluster_Robust_October152013.pdf][Cluster Estimator]], [[./readings/Moore.2012.pdf][Block]][[https://cran.r-project.org/web/packages/blockTools/index.html][Tools]]                                      | [[./assignments/essays/essay2][Essay 2 draft]]            |
|    5 | Covariates and Regression               | MM 1, FE 4.1-3, MM 2, [[./readings/MHE_chapter_2.pdf][MHE p. 16-24]]              | [[./readings/Opower.pdf][Opower]] (O): FE Appendix B (p. 453)                                      | [[./assignments/README.md][PS 2]]                     |
|    6 | Regression; Multi-factor Experiments    | MM 6.1, MM 95-97, FE 9.3.3, 9.4                 | [[./readings/Montgomery.2016.pdf][Montgomery]] Sections 1, 3.0, 3.1, 3.2, 3.5, 4.2, Skim 5                  | Vote on Projects         |
|    7 | HTE                                     | FE 9, [[./readings/clark_sells_2016.pdf][Multiple Comparisons]], and [[./week_07/clark_sells_2016.R][Demo]]            | [[./readings/Goodson_Quibit.pdf][Goodson]] (O): [[./readings/jlr-location-location-location.pdf][JLR]] 1, 2, 3.1, 4.3, [[https://codeascraft.com/2018/10/03/how-etsy-handles-peeking-in-a-b-testing/][Etsy]]                                   | --                       |
|    8 | Incomplete Control of Delivery          | FE 5                                            | [[./readings/GerberGreen.2005.pdf][G&G 2005]]; [[./readings/trochim_donnelly_ch_7.pdf][TD, Ch 7]]; [[./readings/trochim_donnelly_ch_9.pdf][TD, Ch 9]]                                            | [[./assignments/README.md][PS 3]]                     |
|    9 | Spillover                               | FE 8 and [[https://eng.lyft.com/experimentation-in-a-ridesharing-marketplace-b39db027a66e#.dqcrp06rl][lyft]] and (O) [[./readings/Cohen.2016.pdf][uber]]                      | [[./readings/Miguel.2004.pdf][Miguel and Kremer]]; [[./readings/Blake.2014.pdf][Blake and Cohey 2, 3]]                                 | [[./assignments/peerEvaluation/earlyProgress.org][Progress Report]]          |
|   10 | Problems, Diagnostics and the Long View | FE 11.3                                         | [[./readings/DinardoPischke_1997.pdf][DiNardo and Pischke]], [[./readings/Simonsohn.2014.pdf][Simonsohn]] (O): [[http://varianceexplained.org/r/bayesian-ab-testing/][Robinson]]                            | --                       |
|   11 | Causality from Observation?             | MM 3.1, 4.1, 5.1                                | [[http://espin086.wordpress.com/2010/08/08/difference-in-difference-estimation-garbage-incinerators-and-home-prices/][Incinerators]], [[./readings/Glynn.2014.pdf][Glynn]], [[./readings/Dee.2015.pdf][Dee]] (O): [[https://medium.com/teconomics-blog/5-tricks-when-ab-testing-is-off-the-table-f2637e9f15a5][Glassberg Sands]], [[./readings/Lalive.2006.pdf][Lalive]], [[./readings/Rubin.2008.pdf][Rubin, Section 3]] | [[./assignments/README.md][PS 4]]                     |
|   12 | Attrition, Mediation, Generalizabilty   | FE 7, 10, [[./readings/bates_2017.pdf][Bates 2017]]                            | [[./readings/Allcott.2014.pdf][Alcott and Rogers]]                                                       | [[./assignments/peerEvaluation/peerEvaluation1.org][Peer Eval 1]]              |
|   13 | Creative Experiments                    | FE 12, (O): [[https://www.thecut.com/2015/05/how-a-grad-student-uncovered-a-huge-fraud.html][Ny Mag]], [[http://www.sciencemag.org/news/2016/04/real-time-talking-people-about-gay-and-transgender-issues-can-change-their-prejudices][Science]], FE 13              | [[./readings/broockman_irregular.pdf][Broockman Irregularities]], [[./readings/Hughes.2017.pdf][Hughes et al.]] (O): [[https://eng.uber.com/xp/][Uber Platform]]              |                          |
|   14 | Final Thoughts                          |                                                 | [[./readings/Freedman_1991.pdf][Freedman]]                                                                | [[./assignments/README.md][PS 5]]                     |
|   15 | --                                      | [[./readings/retracted_lacour.pdf][(O): Retracted LaCour]], ([[https://www.nytimes.com/2014/12/12/health/gay-marriage-canvassing-study-science.html][tl;dr]]), [[https://www.thisamericanlife.org/radio-archives/episode/584/for-your-reconsideration][Podcat (audio))]] |                                                                         | Final Paper, [[./assignments/peerEvaluation/peerEvaluation2.org][Peer Eval 2]] |
|      |                                         |                                                 |                                                                         |                          |

* Description 
This course introduces students to experimentation in data science. Particular attention is paid to the formation of causal questions, and the design and analysis of experiments to provide answers to these questions.  This topic has increased considerably in importance since 1995, as researchers have learned to think creatively about how to generate data in more scientific ways, and developments in information technology has facilitated the development of better data gathering. 

This course *begins* with a discussion of the issues with causal inference based on observational data. We recognize that many of the decisions that we care about, whether they be business related or theoretically motivated, are /essentially/ causal in nature. 

The *center* of the course builds out an understanding of the mechanics of estimating a causal quantity. We present two major inferential paradigms, one new and one you are likely familiar with. We first present _randomization inference_ as a unifying, intuitive inferential paradigm. We then demonstrate how this paradigm sits in complement to the classical frequentist inferential paradigm. These concepts in hand, we turn focus to the design of experiments and place particular focus both answering the question that we set out to answer, and achieving maximally powered experiments through design. 

The *tail* of the course pursues two parallel tracks. In the first, students form a research question that requires a causal answer and design and implement the experiment that best answers this question. At the same time, new content presented in the course focuses on the practical stumbling blocks in running an experiment and the tests to detect these stumbling blocks. 

We hope that each student who completes the course will: 

- Become skeptical about claims of causality.  When faced with a piece of research on observational data, you should be able to tell stories that illustrate possible flaws in the conclusions.
- Understand why experimentation (generating one’s own data by doing deliberate interventions) solves the basic causal-inference problem.  You should be able to describe several examples of successful experiments and what makes you feel confident about their results.
- Appreciate the difference between laboratory experiments and field experiments.
- Appreciate how information systems and websites can be designed to make experimentation easy in the modern online
- Understand how to quantify uncertainty, using confidence intervals and statistical power calculations.
- Understand why control groups and placebos are both important.
- Design, implement, and analyze your own field experiment.
- Appreciate a few examples of what can go wrong in experiments.  Examples include administrative glitches that undo random assignment, inability to fully control the treatment (and failure to take this inability into account), and spillovers between subjects.

Computing is conducted primarily in R.

If you are looking to work on something over the break, between semesters, I [[https://www.datacamp.com/courses/data-table-data-manipulation-r-tutorial][recommend this]] course on `data.table`, created by the package author Matthew Dowle, and available for free at datacamp. 

** Compute Enviornment 
This semester we're using the [[http://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/UCB-MIDS/w241&branch=master&urlpath=rstudio][UCB Datahub]] as our compute backbone. You can get to it [[http://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https://github.com/UCB-MIDS/w241&branch=master&urlpath=rstudio][here]]. This is a minimal instance -- you're capped at 1GB memory, but it is a really nice way to work on async coding without having to start any machinery of your own. You should be able to knit, save, and edit as you like. The courses' upstream repository is /entirely/ segmented from your copy of this, so feel free to make any changes that you want. Note, however, that this also means that changes you make in the datahub will /not/ be present on your own fork of the repository. In other words, things that happen in the datahub, stay in the data hub. 
** Books 
We use two books in this course, and read a third book in the second week. We recommend that you buy a paper copy of the two textbooks (we've chosen textbooks that have a fair price), and would understand if you digitally read the third book. 

- /Field Experiments: Design and Analysis/ is the core textbook for the cousre. It is available at [[https://www.amazon.com/Field-Experiments-Design-Analysis-Interpretation/dp/0393979954/ref=sr_1_1?ie=UTF8&qid=1495560177&sr=8-1&keywords=field+experiments][Amazon]] for $40.
- /Mastering Metrics/ is the secondary textbook for the course. It is available at [[https://www.amazon.com/Mastering-Metrics-Path-Cause-Effect/dp/0691152845/ref=sr_1_sc_1?ie=UTF8&qid=1495560224&sr=8-1-spell&keywords=mastring+metrics][Amazon]] for $20. 
- /More than Good Intentions/ is the third book for the cousre. It is available at [[https://www.amazon.com/More-Than-Good-Intentions-Improving/dp/0452297567/ref=sr_1_1?ie=UTF8&qid=1495560260&sr=8-1&keywords=more+than+good+intentions][Amazon]] for $10, new, or $3 used. But, you could also read this digitally. 

** Articles 
- We have made all the articles we read in the couse available in the repository. However, it is a /great/ practice to get used to establishing a VPN to gain access to all the journal articles that are available through the library subscription service. Instructions for connecting are [[http://www.lib.berkeley.edu/using-the-libraries/vpn][here]]. Journal access is one of the greatest benefits to belonging to a University, we suggest you use it. 

- David has made a *great* resource that has suggestions for further reading. You can access this [[https://docs.google.com/document/d/1IMsGTHmklhvetfJJfEm9dhoFM7bvb-YOkN_6mAM8kFM/edit?usp=sharing][here]].

* Office Hours 

| *Day*     | *Time*      | *Instructor* | 
|-----------+-------------+--------------|
| Monday    | 12:00-1:30p | Alex         |
| Tuesday   | 6:30-8:30p  | Daniel       |
| Wednesday | 3:00-4:00p  | Carson       |
| Wednesday | 5:30-6:30p  | Alex         |
| Thursday  | 2:00-3:00p  | Carson       |
| Thursday  | 5:30-6:30   | Micah        |
 
* Grading and Scoring 

- *Problem Sets* (50%, 10% each) A series of problem sets, mostly drawn from FE, many requiring programming or analysis in R.
  - We encourage you to work together on problem sets, because great learning can come out of helping each other get unstuck.  We ask that each person independently prepare his or her own problem-set writeup, to demonstrate that you have thought through the ideas and calculations and can explain them on your own.  This includes making sure you run any code yourself and can explain how it works.   Collaboration is encouraged, but mere copying will be treated as academic dishonesty.
  - At this point, the course has lived for a number of semesters, and we have shared solution sets each semester. We note in particular that struggling with the problems is a key part of the learning in this course.  Copying from past solutions constitutes academic dishonesty and will be punished as such; you should know that we have included language in the solutions that will make it clear when something has been merely copied rather than understood.
- *Essays* (20%, 10% each) 
- *Class Experiment* (25%) In teams of 3-5 students, carry out an experiment that measures a causal effect of interest. See the `./finalProject/` folder for much more information 
- *Experiment Pilot Data* (5%) Pilot data analysis of distribution of outcome variable and covariate balance check 
